# Activity Summary for 03/05/2025

## 00:37:32
The log shows the development of two Python scripts: `resume_parser.py` and `resume_shortlister.py`,  along with a CSV file (`Test-sheet - Sheet1.csv`) containing candidate data.

`/Users/kushalsingh/git/cursor/Test-sheet - Sheet1.csv`  contains candidate information including name, college, graduation year, current company, experience, CTC, joining time, CV URL, LinkedIn URL, current location, and resume feedback. This file remains unchanged throughout the log.

`resume_parser.py` undergoes multiple revisions between 23:49:32 and 00:31:41 on 03/05/2025.  The core functionality involves downloading resumes from Google Drive URLs provided in the CSV, extracting text using PyPDF2, and using the Ollama API (specified by `OLLAMA_URL` and `OLLAMA_MODEL`) to analyze the text for role transitions within the same company and to extract relevant roles.  Significant changes include:

* **02/05/2025, 23:49:32 & 23:49:42:** Initial versions of `resume_parser.py` are nearly identical, focusing on downloading PDFs from Google Drive links, extracting text, and using Ollama to check for role transitions.
* **03/05/2025, 00:06:48 - 00:31:41:**  Subsequent commits expand the script's capabilities.  The script now incorporates lists of `TIER1_COLLEGES` and `GOOD_COMPANIES`, and new functions are added: `ollama_query` (simplifies Ollama API calls), `extract_roles_with_ollama` (extracts roles and companies from resumes), `is_tier1_college`, `get_matching_good_companies`, `has_sde2_or_senior_role`,  improved `ctc_in_range` and `exp_in_range` functions for better handling of various input formats, and updated logic to incorporate stricter filtering criteria based on these additions.  The main script now iterates through a dataframe, applies multiple filters, and only saves candidates who meet all the conditions.  There's a noticeable improvement in error handling and logging throughout the process.  The final version uses regular expressions (`re`) to improve the `ctc_in_range` function's robustness.


`resume_shortlister.py` is created at 03/05/2025, 00:05:27 and remains unchanged afterwards. It uses OpenAI's API (`openai.api_key`) to filter resumes based on factors like experience, college tier, company reputation, and role transitions, employing functions like  `extract_text_from_pdf`, `check_role_transition`, `check_sde2_title`, `check_tier1_college`, and `check_good_company`, before making a final judgment using an LLM (GPT-4) for borderline cases.  The script uses predefined lists of `TIER1_TAGS` and `GOOD_COMPANIES`.


The overall development pattern shows an iterative process, starting with basic resume parsing and progressing towards a more sophisticated resume shortlisting system with increased functionality and robustness.  The use of external APIs (Ollama and OpenAI) highlights a reliance on external services for complex tasks like natural language processing.  The repeated modifications to `resume_parser.py` reflect a continuous refinement of the resume parsing and analysis logic.


## 01:37:30
The `/Users/kushalsingh/git/cursor/resume_parser.py` file underwent several revisions on March 5th, 2025.  The core functionality remained consistent: parsing resumes from a CSV file ("cursor/SDE3-Platform.csv"), extracting information using the Ollama API, and shortlisting candidates based on criteria such as CTC, experience, role transitions, previous roles, and college attended.


The key changes across the revisions involved improvements to the resume text extraction and CTC range filtering:

* **00:41:44:** Initial version.  Resume text extraction relied solely on `PyPDF2`.  The CTC range was 25-35 Lakhs.  The `has_sde2_or_senior_role` function directly checked for keywords in the role description.

* **00:43:31:** The `has_sde2_or_senior_role` function was renamed to `has_sde2_or_senior_role_ai` and modified to use the Ollama API for role assessment.  This improved the accuracy of identifying relevant roles.

* **00:47:31:** A minor refinement in the `ctc_in_range` function. Instead of summing all numbers in the CTC string, it now only considers the first number to determine the CTC in Lakhs.

* **00:49:29 & 00:49:37:**  A significant improvement in the `extract_text_from_pdf` function was implemented. This version now utilizes `pdfplumber` as the primary method for PDF text extraction, falling back to OCR using `pdf2image` and `pytesseract` only if `pdfplumber` fails. This addresses potential issues with `PyPDF2`'s limitations in handling complex PDFs.  These two timestamps likely reflect minor, quickly fixed bugs or typos in the added code.

* **00:51:15:** The CTC range in the `ctc_in_range` function was adjusted to 19-35 Lakhs.

* **00:52:28:**  The `ctc_in_range` function's documentation was improved, clarifying that it handles various CTC input formats ("30LPA", "3000000", etc.).

* **01:36:44:** The filename generation in the main script was improved.  Instead of using the index from the dataframe, a sanitized version of the candidate's name is used to create the filename, preventing potential issues with invalid characters.

Throughout the revisions, the lists `TIER1_COLLEGES` and `GOOD_COMPANIES` remained unchanged, suggesting these are relatively stable parameters.  The core logic of shortlisting candidates and generating the "shortlisted_candidates.csv" file remained constant.  The use of the Ollama API for tasks such as role transition identification and role extraction is a recurring pattern, demonstrating a reliance on external AI capabilities for complex text analysis.


## 02:47:22
The `/Users/kushalsingh/git/cursor/resume_parser.py` file underwent several revisions on March 5th, 2025.  The core functionality remained consistent: parsing resumes from a CSV file (`cursor/SDE3-Platform_3.csv`, then `cursor/SDE3-Platform_4.csv`, finally `cursor/SDE3-Platform.csv`), downloading PDFs from provided URLs, extracting text (using pdfplumber and falling back to OCR if necessary), and using the Ollama API to analyze the extracted text for specific criteria.

Key changes across revisions include:

* **CSV Filepath Changes:** The script initially read from `SDE3-Platform_3.csv`, then changed to `SDE3-Platform_4.csv`, and finally settled on `SDE3-Platform.csv`. This suggests iterative processing of different datasets.

* **Column Name Cleaning (02:12:06 and later):**  A significant update at 02:12:06 added `df.columns = df.columns.str.strip()` to remove leading/trailing whitespace from column names in the input CSV.

* **Increased Context Window (02:18:46, 02:20:48):** The length of resume text sent to Ollama API for role transition checks increased from 6000 characters to 60000, and then reduced to 20000 characters. This reflects experimentation to find an optimal length for accurate analysis.

* **Debugging Statements (02:20:48, 02:22:31, 02:23:06):**  A series of modifications between 02:20:48 and 02:23:06 added `print` statements within the `check_role_transition_with_ollama` function to improve debugging.  These print statements display the `answer` from the Ollama API call, for better visibility.  This suggests troubleshooting difficulties in correctly interpreting Ollama's responses.

* **Minor changes:**  There were no significant changes in the core logic of functions like `download_pdf`, `extract_text_from_pdf`, `ollama_query`, `extract_roles_with_ollama`, etc.  The main filtering logic based on CTC, experience, role transitions, and roles remained the same throughout the revisions.


In summary, the evolution of the code involved refining data handling (cleaning column names), optimizing the Ollama API interaction (adjusting context window size), and adding debugging statements to improve the script's reliability and efficiency. The primary goal remained consistent: filtering candidates based on specified criteria.
