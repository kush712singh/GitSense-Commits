# Activity Summary for 03/05/2025

## 00:37:32
The log shows the development of two Python scripts: `resume_parser.py` and `resume_shortlister.py`,  along with a CSV file (`Test-sheet - Sheet1.csv`) containing candidate data.

`/Users/kushalsingh/git/cursor/Test-sheet - Sheet1.csv`  contains candidate information including name, college, graduation year, current company, experience, CTC, joining time, CV URL, LinkedIn URL, current location, and resume feedback. This file remains unchanged throughout the log.

`resume_parser.py` undergoes multiple revisions between 23:49:32 and 00:31:41 on 03/05/2025.  The core functionality involves downloading resumes from Google Drive URLs provided in the CSV, extracting text using PyPDF2, and using the Ollama API (specified by `OLLAMA_URL` and `OLLAMA_MODEL`) to analyze the text for role transitions within the same company and to extract relevant roles.  Significant changes include:

* **02/05/2025, 23:49:32 & 23:49:42:** Initial versions of `resume_parser.py` are nearly identical, focusing on downloading PDFs from Google Drive links, extracting text, and using Ollama to check for role transitions.
* **03/05/2025, 00:06:48 - 00:31:41:**  Subsequent commits expand the script's capabilities.  The script now incorporates lists of `TIER1_COLLEGES` and `GOOD_COMPANIES`, and new functions are added: `ollama_query` (simplifies Ollama API calls), `extract_roles_with_ollama` (extracts roles and companies from resumes), `is_tier1_college`, `get_matching_good_companies`, `has_sde2_or_senior_role`,  improved `ctc_in_range` and `exp_in_range` functions for better handling of various input formats, and updated logic to incorporate stricter filtering criteria based on these additions.  The main script now iterates through a dataframe, applies multiple filters, and only saves candidates who meet all the conditions.  There's a noticeable improvement in error handling and logging throughout the process.  The final version uses regular expressions (`re`) to improve the `ctc_in_range` function's robustness.


`resume_shortlister.py` is created at 03/05/2025, 00:05:27 and remains unchanged afterwards. It uses OpenAI's API (`openai.api_key`) to filter resumes based on factors like experience, college tier, company reputation, and role transitions, employing functions like  `extract_text_from_pdf`, `check_role_transition`, `check_sde2_title`, `check_tier1_college`, and `check_good_company`, before making a final judgment using an LLM (GPT-4) for borderline cases.  The script uses predefined lists of `TIER1_TAGS` and `GOOD_COMPANIES`.


The overall development pattern shows an iterative process, starting with basic resume parsing and progressing towards a more sophisticated resume shortlisting system with increased functionality and robustness.  The use of external APIs (Ollama and OpenAI) highlights a reliance on external services for complex tasks like natural language processing.  The repeated modifications to `resume_parser.py` reflect a continuous refinement of the resume parsing and analysis logic.


## 01:37:30
The `/Users/kushalsingh/git/cursor/resume_parser.py` file underwent several revisions on March 5th, 2025.  The core functionality remained consistent: parsing resumes from a CSV file ("cursor/SDE3-Platform.csv"), extracting information using the Ollama API, and shortlisting candidates based on criteria such as CTC, experience, role transitions, previous roles, and college attended.


The key changes across the revisions involved improvements to the resume text extraction and CTC range filtering:

* **00:41:44:** Initial version.  Resume text extraction relied solely on `PyPDF2`.  The CTC range was 25-35 Lakhs.  The `has_sde2_or_senior_role` function directly checked for keywords in the role description.

* **00:43:31:** The `has_sde2_or_senior_role` function was renamed to `has_sde2_or_senior_role_ai` and modified to use the Ollama API for role assessment.  This improved the accuracy of identifying relevant roles.

* **00:47:31:** A minor refinement in the `ctc_in_range` function. Instead of summing all numbers in the CTC string, it now only considers the first number to determine the CTC in Lakhs.

* **00:49:29 & 00:49:37:**  A significant improvement in the `extract_text_from_pdf` function was implemented. This version now utilizes `pdfplumber` as the primary method for PDF text extraction, falling back to OCR using `pdf2image` and `pytesseract` only if `pdfplumber` fails. This addresses potential issues with `PyPDF2`'s limitations in handling complex PDFs.  These two timestamps likely reflect minor, quickly fixed bugs or typos in the added code.

* **00:51:15:** The CTC range in the `ctc_in_range` function was adjusted to 19-35 Lakhs.

* **00:52:28:**  The `ctc_in_range` function's documentation was improved, clarifying that it handles various CTC input formats ("30LPA", "3000000", etc.).

* **01:36:44:** The filename generation in the main script was improved.  Instead of using the index from the dataframe, a sanitized version of the candidate's name is used to create the filename, preventing potential issues with invalid characters.

Throughout the revisions, the lists `TIER1_COLLEGES` and `GOOD_COMPANIES` remained unchanged, suggesting these are relatively stable parameters.  The core logic of shortlisting candidates and generating the "shortlisted_candidates.csv" file remained constant.  The use of the Ollama API for tasks such as role transition identification and role extraction is a recurring pattern, demonstrating a reliance on external AI capabilities for complex text analysis.


## 02:47:22
The `/Users/kushalsingh/git/cursor/resume_parser.py` file underwent several revisions on March 5th, 2025.  The core functionality remained consistent: parsing resumes from a CSV file (`cursor/SDE3-Platform_3.csv`, then `cursor/SDE3-Platform_4.csv`, finally `cursor/SDE3-Platform.csv`), downloading PDFs from provided URLs, extracting text (using pdfplumber and falling back to OCR if necessary), and using the Ollama API to analyze the extracted text for specific criteria.

Key changes across revisions include:

* **CSV Filepath Changes:** The script initially read from `SDE3-Platform_3.csv`, then changed to `SDE3-Platform_4.csv`, and finally settled on `SDE3-Platform.csv`. This suggests iterative processing of different datasets.

* **Column Name Cleaning (02:12:06 and later):**  A significant update at 02:12:06 added `df.columns = df.columns.str.strip()` to remove leading/trailing whitespace from column names in the input CSV.

* **Increased Context Window (02:18:46, 02:20:48):** The length of resume text sent to Ollama API for role transition checks increased from 6000 characters to 60000, and then reduced to 20000 characters. This reflects experimentation to find an optimal length for accurate analysis.

* **Debugging Statements (02:20:48, 02:22:31, 02:23:06):**  A series of modifications between 02:20:48 and 02:23:06 added `print` statements within the `check_role_transition_with_ollama` function to improve debugging.  These print statements display the `answer` from the Ollama API call, for better visibility.  This suggests troubleshooting difficulties in correctly interpreting Ollama's responses.

* **Minor changes:**  There were no significant changes in the core logic of functions like `download_pdf`, `extract_text_from_pdf`, `ollama_query`, `extract_roles_with_ollama`, etc.  The main filtering logic based on CTC, experience, role transitions, and roles remained the same throughout the revisions.


In summary, the evolution of the code involved refining data handling (cleaning column names), optimizing the Ollama API interaction (adjusting context window size), and adding debugging statements to improve the script's reliability and efficiency. The primary goal remained consistent: filtering candidates based on specified criteria.


## 08:34:59
The log shows a single file, `/Users/kushalsingh/git/cursor/resume_parser.py`, undergoing several revisions between 08:09:27 and 08:31:12 on March 5, 2025.  The core functionality remains consistent: parsing resumes from a CSV file ("cursor/SDE3-Platform_4.csv"), downloading them if necessary, extracting text (using pdfplumber and falling back to OCR if needed), and applying several filtering criteria using the Ollama LLM API.

The primary changes across the revisions focus on refining the prompt used within the `check_role_transition_with_ollama` function. Initially, the prompt checked for role changes *within the same company*.  Later versions modified this to check for role transitions *across different companies* as well, reflecting a change in filtering requirements.  This is the most significant change in the code's logic.  The other modifications are primarily removing debugging print statements (`print()` functions).


## 09:35:00
The file `/Users/kushalsingh/git/cursor/resume_parser_ll.py` contains a Python script for parsing resumes and LinkedIn profiles to extract information about a candidate's work experience and education.  The script uses the Ollama API for several tasks, including identifying role transitions, extracting job titles and company names, and checking for specific roles (like SDE2 or Senior Software Engineer).

The script defines functions for:

* **Downloading PDFs:** `download_pdf` handles downloading PDFs from URLs, including Google Drive links.
* **Extracting Text from PDFs:** `extract_text_from_pdf` uses `pdfplumber` and OCR (using `pdf2image` and `pytesseract`) to extract text from PDFs.
* **Ollama API Interaction:**  Several functions use the `ollama_query` function to send prompts to the Ollama API (`llama3` model) for various analysis tasks.  These include:
    * `check_role_transition_with_ollama` and `check_role_transition_with_ollama_linkedin`: Identifying role transitions in resumes and LinkedIn profiles.
    * `extract_roles_with_ollama` and `extract_roles_with_ollama_linkedin`: Extracting roles and companies from resumes and LinkedIn profiles.
    * `has_sde2_or_senior_role_ai` and `has_sde2_or_senior_role_ai_linkedin`: Checking for senior software engineer roles.
* **Data Filtering:** Functions like `is_tier1_college`, `get_matching_good_companies`, `exp_in_range`, and `ctc_in_range` filter data based on predefined lists (TIER1_COLLEGES, GOOD_COMPANIES) and experience/CTC ranges.

The script includes hardcoded lists of Tier 1 colleges (`TIER1_COLLEGES`) and good companies (`GOOD_COMPANIES`). The most significant change is the implementation of various functions leveraging the Ollama API for advanced text processing and analysis of resumes and LinkedIn profiles.  The timestamp of this significant change is 03/05/2025, 09:23:21.  The script also includes a placeholder function (`fetch_linkedin_profile_text`) that will need further implementation for complete LinkedIn profile processing.  The code heavily relies on regular expressions for data extraction and filtering.


## 10:35:00
The log shows the evolution of a Python script (`resume_parser.py` and `resume_parser_new.py`) designed to process resumes.  The core functionality remains consistent across all versions, focusing on downloading resumes from URLs (including Google Drive links), extracting text (using pdfplumber and OCR as fallback), and using the Ollama API to analyze the extracted text for role transitions, extracting roles and companies, and checking for specific criteria like experience and CTC range.

The initial `resume_parser.py` version (10:01:51) lacked a dedicated directory for downloaded resumes.  A significant change occurred between 10:03:36 and 10:24:17, where a `resume_folder`  was created to store downloaded resumes in "cursor/resumes" directory in `resume_parser.py`. This version is also reflected in `resume_parser_new.py` at timestamp 10:24:17.

The final change (10:28:20 and 10:28:58) in `resume_parser_new.py` involved altering the service account key file path to  `'cursor/keys/resume-parser-458619-b2bcd5d06c29.json'`, moving it from the main script directory to a `keys` subdirectory, suggesting a security improvement by separating sensitive information.  No other code changes are visible between these two timestamps.

Throughout the log, the lists `TIER1_COLLEGES` and `GOOD_COMPANIES` remain unchanged, indicating a static set of preferred colleges and companies for filtering candidates.  The script consistently utilizes the Ollama API for natural language processing tasks, suggesting a reliance on external AI services for resume analysis.  The core filtering logic based on CTC, experience, and resume feedback also remains constant.


## 12:35:00
The log shows code changes across three Python files related to resume parsing and screening.  The initial change at 11:55:48 on 03/05/2025 to `sample_downloader.py` introduces a function `download_pdfs_from_drive` that downloads PDF files from Google Drive using OAuth2. It handles authentication, queries for PDFs based on mime type and optional filters, and downloads them into a specified folder, displaying progress.

Next, `resume_parser_new.py` is modified twice, at 11:59:25 and 11:59:39 on the same day.  These changes add significant functionality for resume parsing and screening. The code includes functions to download PDFs from URLs (including Google Drive links), extract text (using `pdfplumber` and OCR as fallback), and query an Ollama LLM (`llama3`) for various tasks. These tasks include: checking for role transitions, extracting roles and companies from resume text, identifying tier 1 college graduates, finding matches with a list of preferred companies, and checking for senior-level software engineering roles.  The code then processes a CSV file ("cursor/SDE3-Platform_4.csv") applying these functions to each resume, presumably to create a shortlist based on specific criteria. There are no substantial differences between the two commits to `resume_parser_new.py`.

Finally, `resume_screener.py` (modified at 12:29:32 on 03/05/2025) incorporates argparse for command-line argument handling. It takes paths to the input CSV, resume download folder, OAuth token JSON, and output shortlisted candidates CSV as arguments. This suggests a refinement to make the script more versatile and easily runnable from the command line.  The core logic for resume processing appears largely unchanged from `resume_parser_new.py`, reusing the same functions for download, text extraction, and LLM queries.  The key difference is the structured input and output via command-line arguments.
